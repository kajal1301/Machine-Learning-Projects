{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personalized Cancer Diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Business Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Problem Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://www.kaggle.com/c/msk-redefining-cancer-treatment/\n",
    "\n",
    "Data: Memorial Sloan Kettering Cancer Center (MSKCC)\n",
    "\n",
    "Download training_variants.zip and training_text.zip from Kaggle.\n",
    "\n",
    "**Context**:-\n",
    "Source:  https://www.kaggle.com/c/msk-redefining-cancer-treatment/discussion/35336#198462\n",
    "\n",
    "**Problem Statement:-**\n",
    "Classify the given genetic variations/mutations based on evidence from text-based clinical literature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Source/Useful Links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some articles and refrence blogs about the problem statement\n",
    "1. https://www.forbes.com/sites/matthewherper/2017/06/03/a-new-cancer-drug-helped-almost-everyone-who-took-it-almost-heres-what-it-teaches-us/#2a44ee2f6b25\n",
    "2. https://www.youtube.com/watch?v=UwbuW7oK8rk\n",
    "3. https://www.youtube.com/watch?v=qxXRKVompI8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Real-World/Business objectives and constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- No latency requirement.\n",
    "- Interpretability is important.\n",
    "- Errors can be very costly.\n",
    "- Probability of a data-point belonging to each class is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Machine Learning Problem Formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Data Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Source:  https://www.kaggle.com/c/msk-redefining-cancer-treatment/data\n",
    "- We have two data files:one contain infromation aboutthe genetic mutations and the other contains the clinical evidence(text) that human experts/pathologists use to classify the genetic mutations.\n",
    "- Both these data files are have a common column called ID\n",
    "- Data file's information:\n",
    "    - Training_variants (ID, Gene, Variations, Class)\n",
    "    - Training_text(ID, Text)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Mapping the real-world problem to an ML Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Type of Machine Learning Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 9 diffrent classes a genetic mutation can be classified into=> Multiclass Classification Problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Performance Metric\n",
    "Metrics:\n",
    "- Multiclass log-loss\n",
    "- Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Machine Learning Objectives and Constraints\n",
    "**Objective\"** Predict the probability of each data-point belonging to each of the nine classes.\n",
    "**Constraints:** \n",
    "- Interpretability\n",
    "- Class Probabilites are needed.\n",
    "- Penalize the errors in class probabilities => Metric is log-loss.\n",
    "- No latency constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Train, CV and Test Datasets\n",
    "Split the dataset randomly into three parts- train, cross validation and test with 64%, 16% and 20% of data respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics.classification import accuracy_score, log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    " \n",
    "import math\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from mlxtend.plotting import plot_decision_regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points: 3321\n",
      "Number of features: 4\n",
      "Features: ['ID' 'Gene' 'Variation' 'Class']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gene</th>\n",
       "      <th>Variation</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>FAM58A</td>\n",
       "      <td>Truncating Mutations</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CBL</td>\n",
       "      <td>W802*</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CBL</td>\n",
       "      <td>Q249E</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CBL</td>\n",
       "      <td>N454D</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CBL</td>\n",
       "      <td>L399V</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID    Gene             Variation  Class\n",
       "0   0  FAM58A  Truncating Mutations      1\n",
       "1   1     CBL                 W802*      2\n",
       "2   2     CBL                 Q249E      2\n",
       "3   3     CBL                 N454D      3\n",
       "4   4     CBL                 L399V      4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= pd.read_csv(\"training_variants\")\n",
    "print('Number of data points:',data.shape[0])\n",
    "print('Number of features:',data.shape[1])\n",
    "print('Features:',data.columns.values)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Reading text data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points: 3321\n",
      "Number of features: 2\n",
      "Features: ['ID' 'Text']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Cyclin-dependent kinases (CDKs) regulate a var...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Abstract Background  Non-small cell lung canc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Abstract Background  Non-small cell lung canc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Recent evidence has demonstrated that acquired...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Oncogenic mutations in the monomeric Casitas B...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                               Text\n",
       "0   0  Cyclin-dependent kinases (CDKs) regulate a var...\n",
       "1   1   Abstract Background  Non-small cell lung canc...\n",
       "2   2   Abstract Background  Non-small cell lung canc...\n",
       "3   3  Recent evidence has demonstrated that acquired...\n",
       "4   4  Oncogenic mutations in the monomeric Casitas B..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_text= pd.read_csv(\"training_text\",sep= \"\\|\\|\",engine=\"python\",names= [\"ID\",\"Text\"],skiprows= 1 )\n",
    "print(\"Number of data points:\",data_text.shape[0])\n",
    "print('Number of features:',data_text.shape[1])\n",
    "print('Features:',data_text.columns.values)\n",
    "data_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Preprocessing the text:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words= set(stopwords.words('english'))\n",
    "def nlp_preprocessing(total_text,index,column):\n",
    "    if type(total_text) is not int:\n",
    "        string= \"\"\n",
    "    total_text= re.sub('[^a-zA-Z0-9\\n]',' ', total_text)\n",
    "    \n",
    "    total_text= re.sub('\\s+',' ',total_text)\n",
    "    total_text= total_text.lower()\n",
    "    \n",
    "    for word in total_text.split():\n",
    "        if word not in stop_words:\n",
    "            string+=word+\" \"\n",
    "                \n",
    "        data_text[column][index]= string\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time= time.clock()\n",
    "for index,row in data_text.iterrows():\n",
    "    if type(row[\"Text\"]) is str:\n",
    "        nlp_preprocessing(row['Text'],index, 'Text') \n",
    "    else:\n",
    "        print('There is no description for',index)\n",
    "print('time taken for processing the text:',time.clock()-start_time,' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result= pd.merge(data,data_text,on=\"ID\",how='left')\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[result.isnull().any(axis= 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.loc[result['Text'].isnull(),'Text']= result['Gene']+ ' '+ result['Variation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[result['ID']== 1109]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Test and Cross Validation Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the dataset into Train, Cross Validation and Test( 60:20:20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y+true= result['Class'].values\n",
    "result.Gene= result.Gene.str.replace('\\s+','_')\n",
    "result.variation= result.variation.str.replace('\\s+','_')\n",
    "                                               \n",
    "#splitting the dataset into train and test by maintaining same dist as output\n",
    "x_train,x_test, y_train, y_test= train_test_split(result, y_true, stratify= y_true, test_size= 0.2)\n",
    "train_data, cv_data, y_train, y_cv= train_test_split(x_train, y_train, stratify= y_train, te3st_size= 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of data points in train data:\", train_data.shape[0])\n",
    "print(\"Number of data points in test data:\", x_test.shape[0])\n",
    "print(\"Number of data points in cross validation data:\", cv_data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution of y_i in train, test and cross validation dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dist= train_data['Class'].value_counts().sortlevel()\n",
    "test_dist= x_test['Class'].value_counts().sortlevel()\n",
    "cv_dist= cv_dqata['Class'].value_counts().sortlevel()\n",
    "\n",
    "my_colors= 'rgbkymc'\n",
    "train_dist.plot(kind= 'bar')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Data points per class:')\n",
    "plt.title(\"Distribution of yi in train data\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "sorted_yi= np.argsort(-train_dist.values)\n",
    "for i in sorted_yi:\n",
    "    print('Number of data points in class',i+1,':',train_dist.values[i],'(',np.round(train_dist.values[i]/train_data.shape[0]*100),3,'%)')\n",
    "print('-'*80)\n",
    "\n",
    "my_colors= 'rgbkymc'\n",
    "test_dist.plot(kind= 'bar')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Data points per class:')\n",
    "plt.title(\"Distribution of yi in test data\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "sorted_yi= np.argsort(-test_dist.values)\n",
    "for i in sorted_yi:\n",
    "    print('Number of data points in class',i+1,':',test_dist.values[i],'(',np.round(test_dist.values[i]/x_test.shape[0]*100),3,'%)')\n",
    "print('-'*80)\n",
    "my_colors= 'rgbkymc'\n",
    "cv_dist.plot(kind= 'bar')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Data points per class:')\n",
    "plt.title(\"Distribution of yi in cross validation data\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "sorted_yi= np.argsort(-train_dist.values)\n",
    "for i in sorted_yi:\n",
    "    print('Number of data points in class',i+1,':',cv_dist.values[i],'(',np.round(cv_dist.values[i]/cv_data.shape[0]*100),3,'%)')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction using Random Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In random Model we generate the NINE class Probabilities randomly such that they sum to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
